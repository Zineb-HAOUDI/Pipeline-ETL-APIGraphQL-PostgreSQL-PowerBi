{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd39fcfb",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: center; background-color:#830707ff; font-family:'Times New Roman'; \n",
    "            color: white; padding: 14px; line-height: 1.4; border-radius:20px\">\n",
    "Pipeline ETL : Conversion, stockage PostgreSQL et modélisation en étoile\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83684299",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color:#257e2aff; font-family:'Times New Roman'; \n",
    "            color: white; padding: 14px; line-height: 1.4; border-radius:20px\">\n",
    "1. Conversion du fichier JSON en CSV\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433451f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes détectées dans l'ordre : ['rowId', 'type', 'attributes.feedstock', 'attributes.manufacturer', 'buyer.nodes.name', 'buyer.nodes.parentCompany.nodes.name', 'feedstock.nodes.asset.descriptionShort', 'feedstock.nodes.rawMaterial.name', 'feedstock.nodes.quantity', 'feedstock.nodes.unit', 'transactionExpectedCertificateNomenclatures.nodes.tradeItem.descriptionShort', 'transactionExpectedCertificateNomenclatures.nodes.type', 'transactionExpectedCertificateNomenclatures.nodes.level', 'produits.nodes.asset.descriptionShort', 'produits.nodes.asset.attributes.gtin', 'produits.nodes.asset.attributes.hsCode', 'produits.nodes.asset.attributes.descriptionShort', 'produits.nodes.asset.attributes.regulatedProductName', 'produits.nodes.value', 'produits.nodes.unit', 'attributes.type', 'attributes.millsTracabilityPo', 'attributes.millsTracabilityPko', 'attributes.plantationsTracabilityPo', 'attributes.plantationsTracabilityPko', 'point_of_contact.nodes.name', 'attributes.sellingManufacturerFacilityName', 'attributes.volumeContact', 'attributes.buyerNameContact', 'attributes.manufacturerContact', 'attributes.trader', 'attributes.traderContact', 'attributes', 'produits.nodes.asset.attributes.category', 'produits.nodes.asset.attributes.isComponent', 'produits.nodes.asset.attributes.productLine', 'produits.nodes.asset.attributes.countryOfOrigin']\n",
      "✅ Export terminé : 37 colonnes exportées dans l'ordre JSON\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# === 1. Charger le fichier JSON ===\n",
    "with open(r\"result_for_query_purchase_order3.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "rows = data[\"data\"][\"biztransactions\"][\"nodes\"]\n",
    "\n",
    "# === 2. Fonction pour explorer les clés dans l'ordre ===\n",
    "def explore_value_keys(obj, prefix=\"\"):\n",
    "    keys = []\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            new_prefix = f\"{prefix}.{k}\" if prefix else k\n",
    "            if isinstance(v, (str, int, float, bool)) or v is None:\n",
    "                keys.append(new_prefix)\n",
    "            else:\n",
    "                keys.extend(explore_value_keys(v, new_prefix))\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            keys.extend(explore_value_keys(item, prefix))\n",
    "    return keys\n",
    "\n",
    "# === 3. Récupérer toutes les colonnes dans l'ordre d'apparition ===\n",
    "ordered_columns = []\n",
    "for row in rows:\n",
    "    for key in explore_value_keys(row):\n",
    "        if key not in ordered_columns:\n",
    "            ordered_columns.append(key)\n",
    "\n",
    "print(\"Colonnes détectées dans l'ordre :\", ordered_columns)\n",
    "\n",
    "# === 4. Fonction générique pour extraire les valeurs ===\n",
    "def extract_nested_values(data, path):\n",
    "    results = []\n",
    "\n",
    "    def recurse(node, keys):\n",
    "        if not keys:\n",
    "            # Si valeur simple → on ajoute directement\n",
    "            if isinstance(node, (str, int, float, bool)):\n",
    "                results.append(node)   \n",
    "            return\n",
    "        key = keys[0]\n",
    "        if isinstance(node, dict) and key in node:\n",
    "            recurse(node[key], keys[1:])\n",
    "        elif isinstance(node, list):\n",
    "            for item in node:\n",
    "                recurse(item, keys)\n",
    "\n",
    "    recurse(data, path)\n",
    "\n",
    "    \n",
    "    # - Si plusieurs valeurs -> on garde une liste\n",
    "    # - Si une seule valeur -> on garde la valeur directement\n",
    "    if not results:\n",
    "        return None\n",
    "    elif len(results) == 1:\n",
    "        return results[0]\n",
    "    else:\n",
    "        return results   # ← garde une vraie liste Python\n",
    "\n",
    "# === 5. Construire le tableau avec les colonnes dans l'ordre ===\n",
    "records = []\n",
    "for row in rows:\n",
    "    record = {}\n",
    "    for col in ordered_columns:\n",
    "        path = col.split(\".\")\n",
    "        record[col] = extract_nested_values(row, path)\n",
    "    records.append(record)\n",
    "\n",
    "df = pd.DataFrame(records, columns=ordered_columns)\n",
    "# === 6. Explosion automatique des colonnes qui contiennent des listes ===\n",
    "for col in df.columns:\n",
    "    if df[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        df = df.explode(col, ignore_index=True)\n",
    "\n",
    "\n",
    "print(f\"✅ Export terminé : {len(ordered_columns)} colonnes exportées dans l'ordre JSON\")\n",
    "\n",
    "# === 6. Export CSV\n",
    "# les colonnes avec des listes seront écrites comme \"[a, b, c]\" dans le CSV\n",
    "df.to_csv(r\"purchase_orders_full_flat37 ordered.csv\",\n",
    "          sep=\";\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7188564e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color:#257e2aff; font-family:'Times New Roman'; \n",
    "            color: white; padding: 14px; line-height: 1.4; border-radius:20px\">\n",
    "2. Anonymisation des données\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393fa59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV anonymisé écrit : C:\\Program Files\\PostgreSQL\\16\\data\\Projet Vital\\purchase_orders_full_flat37_anonymized.csv\n",
      "✅ Mapping noms écrit : C:\\Program Files\\PostgreSQL\\16\\data\\Projet Vital\\anonymization_mapping.csv\n",
      "✅ Mapping IDs écrit : C:\\Program Files\\PostgreSQL\\16\\data\\Projet Vital\\id_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import os\n",
    "\n",
    "# --- Faker en anglais  ---\n",
    "fake = Faker(\"en_US\")\n",
    "\n",
    "# --- Fichiers ---\n",
    "INPUT_CSV  = r\"purchase_orders_full_flat37 ordered.csv\"\n",
    "OUTPUT_CSV = r\"purchase_orders_full_flat37_anonymized.csv\"\n",
    "MAPPING_CSV = r\"anonymization_mapping.csv\"\n",
    "ID_MAPPING_CSV = r\"id_mapping.csv\"\n",
    "\n",
    "# --- Colonnes à anonymiser (noms) ---\n",
    "COLS = [\n",
    "    \"attributes.manufacturer\",\n",
    "    \"buyer.nodes.name\",\n",
    "    \"buyer.nodes.parentCompany.nodes.name\",\n",
    "    \"point_of_contact.nodes.name\",\n",
    "    \"attributes.sellingManufacturerFacilityName\",\n",
    "    \"attributes.trader\",\n",
    "]\n",
    "\n",
    "# --- Colonnes identifiants ---\n",
    "ID_COLS = [\n",
    "    \"rowId\",\n",
    "    \"produits.nodes.asset.attributes.gtin\",\n",
    "    \"produits.nodes.asset.attributes.hsCode\",\n",
    "]\n",
    "\n",
    "# --- Charger mapping existant si présent ---\n",
    "ANONYMIZED_VALUES = {}\n",
    "if os.path.exists(MAPPING_CSV):\n",
    "    old_map = pd.read_csv(MAPPING_CSV, dtype=str)\n",
    "    for _, row in old_map.iterrows():\n",
    "        ANONYMIZED_VALUES[row[\"original\"]] = row[\"anonymized\"]\n",
    "\n",
    "# --- Charger mapping identifiants ---\n",
    "ID_MAP = {}\n",
    "ID_COUNTER = {\"PO\": 0, \"GTIN\": 0, \"HS\": 0}\n",
    "if os.path.exists(ID_MAPPING_CSV):\n",
    "    idmap_df = pd.read_csv(ID_MAPPING_CSV, dtype=str)\n",
    "    for _, r in idmap_df.iterrows():\n",
    "        ID_MAP[r[\"original\"]] = {\"fake\": r[\"fake\"], \"type\": r[\"id_type\"]}\n",
    "        # Mise à jour compteur\n",
    "        if r[\"id_type\"] in ID_COUNTER:\n",
    "            try:\n",
    "                num = int(r[\"fake\"].split(\"_\")[-1])\n",
    "                ID_COUNTER[r[\"id_type\"]] = max(ID_COUNTER[r[\"id_type\"]], num)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# --- Fonctions ---\n",
    "def fake_value(original, col):\n",
    "    \"\"\"Anonymisation des noms (entreprises, contacts, etc.)\"\"\"\n",
    "    if pd.isna(original) or str(original).strip() == \"\":\n",
    "        return \"\"   # on garde vide si vide à l'origine\n",
    "\n",
    "    if original not in ANONYMIZED_VALUES:\n",
    "        if \"buyer\" in col or \"trader\" in col:\n",
    "            new_val = fake.company()\n",
    "        elif \"manufacturer\" in col or \"sellingManufacturerFacilityName\" in col:\n",
    "            new_val = fake.company() + \" Manufacturing\"\n",
    "        elif \"point_of_contact\" in col:\n",
    "            new_val = fake.name()\n",
    "        else:\n",
    "            new_val = fake.word().capitalize()\n",
    "        ANONYMIZED_VALUES[original] = new_val\n",
    "\n",
    "    return ANONYMIZED_VALUES[original]\n",
    "\n",
    "\n",
    "def _fmt(seq, width=6):\n",
    "    return str(seq).zfill(width)\n",
    "\n",
    "def anonymize_id_value(original, col):\n",
    "    \"\"\"Anonymisation des identifiants (rowId, gtin, hsCode)\"\"\"\n",
    "    if original is None or str(original).strip() in [\"\", \"nan\", \"NaN\", \"null\", \"None\"]:\n",
    "        return \"\"\n",
    "\n",
    "    orig = str(original).strip()\n",
    "    if orig in ID_MAP:\n",
    "        return ID_MAP[orig][\"fake\"]\n",
    "\n",
    "    if col == \"rowId\":\n",
    "        ID_COUNTER[\"PO\"] += 1\n",
    "        fakev = f\"PO_{_fmt(ID_COUNTER['PO'])}\"\n",
    "        id_type = \"PO\"\n",
    "    elif \"gtin\" in col.lower():\n",
    "        ID_COUNTER[\"GTIN\"] += 1\n",
    "        fakev = f\"FAKE_GTIN_{_fmt(ID_COUNTER['GTIN'])}\"\n",
    "        id_type = \"GTIN\"\n",
    "    elif \"hs\" in col.lower():\n",
    "        ID_COUNTER[\"HS\"] += 1\n",
    "        fakev = f\"FAKE_HS_{_fmt(ID_COUNTER['HS'])}\"\n",
    "        id_type = \"HS\"\n",
    "    else:\n",
    "        fakev = f\"FAKE_{hash(orig) % 1000000}\"\n",
    "        id_type = \"OTHER\"\n",
    "\n",
    "    ID_MAP[orig] = {\"fake\": fakev, \"type\": id_type}\n",
    "    return fakev\n",
    "\n",
    "# --- Traitement par chunks ---\n",
    "chunksize = 100_000\n",
    "first = True\n",
    "\n",
    "for chunk in pd.read_csv(INPUT_CSV, sep=\";\", dtype=str, chunksize=chunksize, low_memory=False, encoding=\"utf-8\"):\n",
    "    # anonymiser noms\n",
    "    for col in COLS:\n",
    "        if col in chunk.columns:\n",
    "            chunk[col] = chunk[col].apply(lambda x: fake_value(x, col))\n",
    "\n",
    "    # anonymiser identifiants\n",
    "    for col in ID_COLS:\n",
    "        if col in chunk.columns:\n",
    "            chunk[col] = chunk[col].apply(lambda x: anonymize_id_value(x, col))\n",
    "\n",
    "    # écrire fichier\n",
    "    chunk.to_csv(OUTPUT_CSV, sep=\";\", index=False, encoding=\"utf-8\", mode=\"w\" if first else \"a\", header=first)\n",
    "    first = False\n",
    "\n",
    "# --- Sauvegarde mapping noms ---\n",
    "map_df = pd.DataFrame([{\"original\": k, \"anonymized\": v} for k, v in ANONYMIZED_VALUES.items()])\n",
    "map_df.to_csv(MAPPING_CSV, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# --- Sauvegarde mapping identifiants ---\n",
    "if ID_MAP:\n",
    "    rows = [{\"original\": k, \"fake\": v[\"fake\"], \"id_type\": v[\"type\"]} for k, v in ID_MAP.items()]\n",
    "    idmap_df = pd.DataFrame(rows)\n",
    "    idmap_df.to_csv(ID_MAPPING_CSV, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"✅ CSV anonymisé écrit : {OUTPUT_CSV}\")\n",
    "print(f\"✅ Mapping noms écrit : {MAPPING_CSV}\")\n",
    "print(f\"✅ Mapping IDs écrit : {ID_MAPPING_CSV}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fc9da2",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color:#257e2aff; font-family:'Times New Roman'; \n",
    "            color: white; padding: 14px; line-height: 1.4; border-radius:20px\">\n",
    "3. Échantillonnage des données\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf058f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Échantillon de 10000 lignes créé : C:\\Program Files\\PostgreSQL\\16\\data\\Projet Vital\\purchase_orders_sample_random.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "INPUT_CSV = r\"purchase_orders_full_flat37_anonymized.csv\"\n",
    "OUTPUT_CSV = r\"purchase_orders_sample_random.csv\"\n",
    "\n",
    "# Nombre de lignes à garder\n",
    "N = 100000   # tu peux mettre 5000 ou 20000 si tu veux\n",
    "\n",
    "# Charger seulement N lignes\n",
    "df = pd.read_csv(INPUT_CSV, sep=\";\", nrows=N)\n",
    "\n",
    "# Sauvegarder l'échantillon\n",
    "df.to_csv(OUTPUT_CSV, sep=\";\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"✅ Échantillon de {N} lignes créé : {OUTPUT_CSV}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232de7b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color:#257e2aff; font-family:'Times New Roman';\n",
    "            color: white; padding: 14px; line-height: 1.4; border-radius:20px;\">\n",
    "4. Création de la base Projet sur PostgreSQL et chargement des données\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Base 'Projet' supprimée et recréée avec succès\n",
      "✅ Données CSV importées dans PostgreSQL (staging_orders)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Charger les variables depuis le fichier .env\n",
    "load_dotenv()\n",
    "\n",
    "# === 1. Charger le fichier CSV ===\n",
    "csv_file = r\"purchase_orders_sample_random.csv\"\n",
    "df = pd.read_csv(csv_file, sep=\";\")\n",
    "\n",
    "numeric_cols = [\n",
    "    \"produits.nodes.value\",\n",
    "    \"feedstock.nodes.quantity\",\n",
    "    \"attributes.millsTracabilityPo\",\n",
    "    \"attributes.millsTracabilityPko\",\n",
    "    \"attributes.plantationsTracabilityPo\",\n",
    "    \"attributes.plantationsTracabilityPko\",\n",
    "    \"attributes.volumeContact\"\n",
    "]\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# === 2. Supprimer et recréer la base Projet ===\n",
    "#  AUTOCOMMIT pour DROP/CREATE DATABASE\n",
    "# Lire le mot de passe dans la variable d’environnement\n",
    "password = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "\n",
    "admin_engine = create_engine(\n",
    "    f\"postgresql+psycopg2://postgres:{password}@localhost:5432/postgres\",\n",
    "    isolation_level=\"AUTOCOMMIT\"\n",
    ")\n",
    "\n",
    "with admin_engine.begin() as conn:\n",
    "    # Fermer toutes les connexions actives sur Projet\n",
    "    conn.execute(text(\"\"\"\n",
    "        SELECT pg_terminate_backend(pid)\n",
    "        FROM pg_stat_activity\n",
    "        WHERE datname = 'Projet' AND pid <> pg_backend_pid();\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Supprimer puis recréer la base\n",
    "    conn.execute(text('DROP DATABASE IF EXISTS \"Projet\";'))\n",
    "    conn.execute(text(\"CREATE DATABASE \\\"Projet\\\" WITH ENCODING 'UTF8' TEMPLATE template1;\"))\n",
    "\n",
    "print(\"🗑️ Base 'Projet' supprimée et recréée avec succès\")\n",
    "\n",
    "# === 3. Connexion à la nouvelle base Projet ===\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://postgres:{password}@localhost:5432/Projet\"\n",
    ")\n",
    "\n",
    "\n",
    "# === 4. Charger le CSV dans une table de staging ===\n",
    "df.to_sql(\"staging_orders\", engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"✅ Données CSV importées dans PostgreSQL (staging_orders)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be96b0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color:#257e2aff; font-family:'Times New Roman';\n",
    "            color: white; padding: 14px; line-height: 1.4; border-radius:20px;\">\n",
    "5. Création des tables pour la modélisation en étoile\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4589e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tables de dimensions et de faits créées dans PostgreSQL\n"
     ]
    }
   ],
   "source": [
    "# === 4. Créer les tables de dimensions et de faits ===\n",
    "# === 4. Créer les tables de dimensions et de faits ===\n",
    "schema_sql = \"\"\"\n",
    "\n",
    "DROP TABLE IF EXISTS Fact_Orders CASCADE;\n",
    "DROP SEQUENCE IF EXISTS fact_orders_id_fact_seq CASCADE;\n",
    "DROP TABLE IF EXISTS Dim_Manufacturer CASCADE;\n",
    "DROP TABLE IF EXISTS Dim_PointOfContact CASCADE;\n",
    "DROP TABLE IF EXISTS Dim_Trader CASCADE;\n",
    "DROP TABLE IF EXISTS Dim_Certification CASCADE;\n",
    "DROP TABLE IF EXISTS Dim_Feedstock CASCADE;\n",
    "DROP TABLE IF EXISTS Dim_Product CASCADE;\n",
    "DROP TABLE IF EXISTS Dim_Buyer CASCADE;\n",
    "\n",
    "-- Table des acheteurs\n",
    "CREATE TABLE IF NOT EXISTS Dim_Buyer (\n",
    "    id_buyer SERIAL PRIMARY KEY,\n",
    "    \"buyer.nodes.name\" TEXT,\n",
    "    \"buyer.nodes.parentCompany.nodes.name\" TEXT,\n",
    "    \"attributes.buyerNameContact\" TEXT\n",
    ");\n",
    "\n",
    "-- Table des produits\n",
    "CREATE TABLE IF NOT EXISTS Dim_Product (\n",
    "    id_product SERIAL PRIMARY KEY,\n",
    "    \"produits.nodes.asset.descriptionShort\" TEXT,\n",
    "    \"produits.nodes.asset.attributes.gtin\" TEXT,\n",
    "    \"produits.nodes.asset.attributes.hsCode\" TEXT,\n",
    "    \"produits.nodes.asset.attributes.descriptionShort\" TEXT,\n",
    "    \"produits.nodes.asset.attributes.regulatedProductName\" TEXT,\n",
    "    \"produits.nodes.unit\" TEXT,\n",
    "    \"produits.nodes.asset.attributes.category\" TEXT,\n",
    "    \"produits.nodes.asset.attributes.isComponent\" TEXT,\n",
    "    \"produits.nodes.asset.attributes.productLine\" TEXT,\n",
    "    \"produits.nodes.asset.attributes.countryOfOrigin\" TEXT\n",
    ");\n",
    "\n",
    "-- Table des matières premières\n",
    "CREATE TABLE IF NOT EXISTS Dim_Feedstock (\n",
    "    id_feedstock SERIAL PRIMARY KEY,\n",
    "    \"attributes.feedstock\" TEXT,\n",
    "    \"feedstock.nodes.asset.descriptionShort\" TEXT,\n",
    "    \"feedstock.nodes.rawMaterial.name\" TEXT,\n",
    "    \"feedstock.nodes.unit\" TEXT\n",
    ");\n",
    "\n",
    "-- Table des certifications\n",
    "CREATE TABLE IF NOT EXISTS Dim_Certification (\n",
    "    id_certification SERIAL PRIMARY KEY,\n",
    "    \"transactionExpectedCertificateNomenclatures.nodes.tradeItem.descriptionShort\" TEXT,\n",
    "    \"transactionExpectedCertificateNomenclatures.nodes.type\" TEXT,\n",
    "    \"transactionExpectedCertificateNomenclatures.nodes.level\" TEXT\n",
    ");\n",
    "\n",
    "-- Table des traders\n",
    "CREATE TABLE IF NOT EXISTS Dim_Trader (\n",
    "    id_trader SERIAL PRIMARY KEY,\n",
    "    \"attributes.trader\" TEXT,\n",
    "    \"attributes.traderContact\" TEXT\n",
    ");\n",
    "\n",
    "-- Table des points de contact\n",
    "CREATE TABLE IF NOT EXISTS Dim_PointOfContact (\n",
    "    id_poc SERIAL PRIMARY KEY,\n",
    "    \"point_of_contact.nodes.name\" TEXT\n",
    ");\n",
    "\n",
    "-- Table des fabricants\n",
    "CREATE TABLE IF NOT EXISTS Dim_Manufacturer (\n",
    "    id_manufacturer SERIAL PRIMARY KEY,\n",
    "    \"attributes.sellingManufacturerFacilityName\" TEXT,\n",
    "    \"attributes.manufacturer\" TEXT,\n",
    "    \"attributes.manufacturerContact\" TEXT\n",
    ");\n",
    "\n",
    "-- Table des faits (transactions)\n",
    "CREATE TABLE IF NOT EXISTS Fact_Orders (\n",
    "    id_fact SERIAL PRIMARY KEY,\n",
    "    \"rowId\" TEXT,\n",
    "    \"type\" TEXT,\n",
    "    id_buyer INT REFERENCES Dim_Buyer(id_buyer),\n",
    "    id_product INT REFERENCES Dim_Product(id_product),\n",
    "    id_feedstock INT REFERENCES Dim_Feedstock(id_feedstock),\n",
    "    id_certification INT REFERENCES Dim_Certification(id_certification),\n",
    "    id_trader INT REFERENCES Dim_Trader(id_trader),\n",
    "    id_poc INT REFERENCES Dim_PointOfContact(id_poc),\n",
    "    id_manufacturer INT REFERENCES Dim_Manufacturer(id_manufacturer),\n",
    "    \"produits.nodes.value\" NUMERIC,\n",
    "    \"feedstock.nodes.quantity\" NUMERIC,\n",
    "    \"attributes.millsTracabilityPo\" NUMERIC,\n",
    "    \"attributes.millsTracabilityPko\" NUMERIC,\n",
    "    \"attributes.plantationsTracabilityPo\" NUMERIC,\n",
    "    \"attributes.plantationsTracabilityPko\" NUMERIC,\n",
    "    \"attributes.volumeContact\" NUMERIC\n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(schema_sql))\n",
    "    conn.commit()\n",
    "\n",
    "print(\"✅ Tables de dimensions et de faits créées dans PostgreSQL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2fa30f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color:#257e2aff; font-family:'Times New Roman';\n",
    "            color: white; padding: 14px; line-height: 1.4; border-radius:20px;\">\n",
    "5. Alimentation des tables avec le fichier de base\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84795453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dimensions alimentées avec succès\n",
      "✅ Table des faits alimentée avec succès\n"
     ]
    }
   ],
   "source": [
    "## === 5. Alimentation des tables de dimensions ===\n",
    "with engine.begin() as conn:\n",
    "    # Buyer\n",
    "    conn.execute(text(\"\"\"\n",
    "        INSERT INTO Dim_Buyer (\"buyer.nodes.name\", \"buyer.nodes.parentCompany.nodes.name\", \"attributes.buyerNameContact\")\n",
    "        SELECT DISTINCT \"buyer.nodes.name\", \"buyer.nodes.parentCompany.nodes.name\", \"attributes.buyerNameContact\"\n",
    "        FROM staging_orders\n",
    "        WHERE \"buyer.nodes.name\" IS NOT NULL;\n",
    "    \"\"\"))\n",
    "\n",
    "    # Product\n",
    "    conn.execute(text(\"\"\"\n",
    "        INSERT INTO Dim_Product (\"produits.nodes.asset.descriptionShort\", \"produits.nodes.asset.attributes.gtin\",\n",
    "            \"produits.nodes.asset.attributes.hsCode\", \"produits.nodes.asset.attributes.descriptionShort\",\n",
    "            \"produits.nodes.asset.attributes.regulatedProductName\", \"produits.nodes.unit\",\n",
    "            \"produits.nodes.asset.attributes.category\", \"produits.nodes.asset.attributes.isComponent\",\n",
    "            \"produits.nodes.asset.attributes.productLine\", \"produits.nodes.asset.attributes.countryOfOrigin\")\n",
    "        SELECT DISTINCT \"produits.nodes.asset.descriptionShort\", \"produits.nodes.asset.attributes.gtin\",\n",
    "            \"produits.nodes.asset.attributes.hsCode\", \"produits.nodes.asset.attributes.descriptionShort\",\n",
    "            \"produits.nodes.asset.attributes.regulatedProductName\", \"produits.nodes.unit\",\n",
    "            \"produits.nodes.asset.attributes.category\", \"produits.nodes.asset.attributes.isComponent\",\n",
    "            \"produits.nodes.asset.attributes.productLine\", \"produits.nodes.asset.attributes.countryOfOrigin\"\n",
    "        FROM staging_orders;\n",
    "    \"\"\"))\n",
    "\n",
    "    # Feedstock\n",
    "    conn.execute(text(\"\"\"\n",
    "        INSERT INTO Dim_Feedstock (\"attributes.feedstock\", \"feedstock.nodes.asset.descriptionShort\",\n",
    "            \"feedstock.nodes.rawMaterial.name\", \"feedstock.nodes.unit\")\n",
    "        SELECT DISTINCT \"attributes.feedstock\", \"feedstock.nodes.asset.descriptionShort\",\n",
    "            \"feedstock.nodes.rawMaterial.name\", \"feedstock.nodes.unit\"\n",
    "        FROM staging_orders;\n",
    "    \"\"\"))\n",
    "\n",
    "    # Certification\n",
    "    conn.execute(text(\"\"\"\n",
    "        INSERT INTO Dim_Certification (\"transactionExpectedCertificateNomenclatures.nodes.tradeItem.descriptionShort\",\n",
    "            \"transactionExpectedCertificateNomenclatures.nodes.type\",\n",
    "            \"transactionExpectedCertificateNomenclatures.nodes.level\")\n",
    "        SELECT DISTINCT \"transactionExpectedCertificateNomenclatures.nodes.tradeItem.descriptionShort\",\n",
    "            \"transactionExpectedCertificateNomenclatures.nodes.type\",\n",
    "            \"transactionExpectedCertificateNomenclatures.nodes.level\"\n",
    "        FROM staging_orders;\n",
    "    \"\"\"))\n",
    "\n",
    "    # Trader\n",
    "    conn.execute(text(\"\"\"\n",
    "        INSERT INTO Dim_Trader (\"attributes.trader\", \"attributes.traderContact\")\n",
    "        SELECT DISTINCT \"attributes.trader\", \"attributes.traderContact\"\n",
    "        FROM staging_orders;\n",
    "    \"\"\"))\n",
    "\n",
    "    # Point of Contact\n",
    "    conn.execute(text(\"\"\"\n",
    "        INSERT INTO Dim_PointOfContact (\"point_of_contact.nodes.name\")\n",
    "        SELECT DISTINCT \"point_of_contact.nodes.name\"\n",
    "        FROM staging_orders;\n",
    "    \"\"\"))\n",
    "\n",
    "    # Manufacturer\n",
    "    conn.execute(text(\"\"\"\n",
    "        INSERT INTO Dim_Manufacturer (\"attributes.sellingManufacturerFacilityName\",\n",
    "            \"attributes.manufacturer\", \"attributes.manufacturerContact\")\n",
    "        SELECT DISTINCT \"attributes.sellingManufacturerFacilityName\",\n",
    "            \"attributes.manufacturer\", \"attributes.manufacturerContact\"\n",
    "        FROM staging_orders;\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"✅ Dimensions alimentées avec succès\")\n",
    "\n",
    "\n",
    "# === 6. Alimentation de la table des faits ===\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        INSERT INTO Fact_Orders (\n",
    "            \"rowId\", \"type\",\n",
    "            id_buyer, id_product, id_feedstock, id_certification, id_trader, id_poc, id_manufacturer,\n",
    "            \"produits.nodes.value\", \"feedstock.nodes.quantity\",\n",
    "            \"attributes.millsTracabilityPo\", \"attributes.millsTracabilityPko\",\n",
    "            \"attributes.plantationsTracabilityPo\", \"attributes.plantationsTracabilityPko\",\n",
    "            \"attributes.volumeContact\"\n",
    "        )\n",
    "        SELECT\n",
    "            staging_orders.\"rowId\",\n",
    "            staging_orders.\"type\",\n",
    "            Dim_Buyer.id_buyer,\n",
    "            Dim_Product.id_product,\n",
    "            Dim_Feedstock.id_feedstock,\n",
    "            Dim_Certification.id_certification,\n",
    "            Dim_Trader.id_trader,\n",
    "            Dim_PointOfContact.id_poc,\n",
    "            Dim_Manufacturer.id_manufacturer,\n",
    "            staging_orders.\"produits.nodes.value\",\n",
    "            staging_orders.\"feedstock.nodes.quantity\",\n",
    "            staging_orders.\"attributes.millsTracabilityPo\",\n",
    "            staging_orders.\"attributes.millsTracabilityPko\",\n",
    "            staging_orders.\"attributes.plantationsTracabilityPo\",\n",
    "            staging_orders.\"attributes.plantationsTracabilityPko\",\n",
    "            staging_orders.\"attributes.volumeContact\"\n",
    "        FROM staging_orders\n",
    "        LEFT JOIN Dim_Buyer\n",
    "            ON staging_orders.\"buyer.nodes.name\" = Dim_Buyer.\"buyer.nodes.name\"\n",
    "        LEFT JOIN Dim_Product\n",
    "            ON staging_orders.\"produits.nodes.asset.descriptionShort\" = Dim_Product.\"produits.nodes.asset.descriptionShort\"\n",
    "        LEFT JOIN Dim_Feedstock\n",
    "            ON staging_orders.\"attributes.feedstock\" = Dim_Feedstock.\"attributes.feedstock\"\n",
    "        LEFT JOIN Dim_Certification\n",
    "            ON staging_orders.\"transactionExpectedCertificateNomenclatures.nodes.tradeItem.descriptionShort\" = Dim_Certification.\"transactionExpectedCertificateNomenclatures.nodes.tradeItem.descriptionShort\"\n",
    "        LEFT JOIN Dim_Trader\n",
    "            ON staging_orders.\"attributes.trader\" = Dim_Trader.\"attributes.trader\"\n",
    "        LEFT JOIN Dim_PointOfContact\n",
    "            ON staging_orders.\"point_of_contact.nodes.name\" = Dim_PointOfContact.\"point_of_contact.nodes.name\"\n",
    "        LEFT JOIN Dim_Manufacturer\n",
    "            ON staging_orders.\"attributes.manufacturer\" = Dim_Manufacturer.\"attributes.manufacturer\";\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"✅ Table des faits alimentée avec succès\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
